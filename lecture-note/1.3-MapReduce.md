# 1.3 MapReduce

## MapReduce의 3대 원리

### MapReduce 기법

1. Sort-Merge *부분정렬-전체정렬*
2. Group-By *파티셔닝-그룹핑*
3. Sub-Total *소계-총계*

### MapReduce 단계

1. split: 조각 내기
2. Map(): 사용자 정의 함수
3. shuffle: 1대로 모아주는 역할
4. Reduce(): 사용자 정의 함수이며 Map()과 같은 함수
5. output 저장: hdfs에 저장

## Sub - Total

### 기본

- Map이 만약 3개라면 전체 데이터를 3개로 나누어 할당한다.
- 병렬로 동시에 처리 되기 때문에 걸리는 시간은 "기준 시간 / Map 개수"가 된다.
- 각 Map에서 연산이 끝나면, 결과값을 한 곳으로 모아서 그 결과값들을 사용하여 Reduce를 실행한다.

### 주의할 점

- Map() = Reduce() 이기 때문에 함수를 정의할 때, 어떻게 나누어도 성립하게 해야 한다. (ex. average)
- 슈퍼컴퓨터는 split을 다르게 해서 2번 연산을 진행하고 결과가 다르면 잘못된 계산이라고 여긴다.

## Sort - Merge

### 정렬과 R/W 시간

- 정렬: O(N^2) → 데이터가 늘어나면 걸리는 시간은 점점 더 오래 걸린다.
- R/W: O(N) → 비례

### 예시

- 시간 예시
1. data: 1억 건의 데이터
2. split(10조각): Map 하나 당 1천만 건의 데이터
3. Map(부분정렬): 병렬 처리이므로 100분
4. Shuffle: Reduce 1개가 1억 건의 데이터를 Read 해와야 하므로 10분
5. Reduce(병합정렬): Merge sort는 O(N) → 10분
6. total: 120분 (기준시간 / Map 개수^2 + a)

## Group - By

### 도입

- 무조건 Sort-Merge와 함께 쓰인다.
- 아이디어: 카드가 있으면 모양에 따라 정렬할 수도 있지 않을까? (Reduce가 여러개)

### 예시

- 시간 예시

|건수|정렬 시간|Read, Write 시간|
|1백만 건|1분|0.1분|
|1천만 건|100분|1분|
|1억 건| 10,000분|10분|

1. data: 1억 건의 데이터
2. split(10조각): Map 하나 당 1천만 건의 데이터
3. Partition: 1천만 건의 데이터를 4등분 → 1분 (병렬)
4. Map(정렬)
    - 2500만 건의 데이터 정렬은 100/4^2분이 소요된다.
    - Map 하나 기준 2500만 건의 정렬을 4번 수행하여야 하므로 25분이 소요된다.
    - Map 10개가 병렬로 처리되기 때문에 총 25분이 소요된다.
5. Shuffle: 모양 별로 모으는 과정, 2500만 건을 Read 하는 것은 2.5분이 소요된다.
6. Reduce(모양별 정렬): Shuffle에서 모양 별로 모아진 2500만 건의 데이터를 Merge sort하는 과정으로 2.5분이 소요된다.
7. total: 31분 (기준시간 / Reduce 개수 * Map 개수 ^ 2 + a)